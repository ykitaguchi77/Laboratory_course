{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkff8v05yaE8SFpL1efxFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Laboratory_course/blob/master/12.%20web%E3%82%A2%E3%83%97%E3%83%AA%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Streamlit test app**"
      ],
      "metadata": {
        "id": "mN2YVgvkkPJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WU0aF9uuOjY",
        "outputId": "88f6e519-50aa-4e94-9e72-46d8ca12f3f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KwZ0cx8ZkOgC",
        "outputId": "e12bf444-d453-48ce-e139-a4e756e1dbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.3/829.3 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 1. 必要なライブラリのインストール\n",
        "!pip install streamlit --q\n",
        "!pip install pyngrok --q\n",
        "!pip install streamlit-option-menu --q\n",
        "\n",
        "# 2. ngrokのセットアップ\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ngrokのAuthtoken設定 (初回のみ必要)\n",
        "ngrok.set_auth_token('ngrok api code here')\n",
        "\n",
        "# 3. サンプルのStreamlitアプリケーション作成\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/drive/MyDrive/AI_laboratory_course/classification.pth\", \"/content\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s3QHNmzCubto",
        "outputId": "0c9c4eb4-616a-4177-8443-4fb97f044bd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/classification.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# モデルの定義\n",
        "class FruitClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FruitClassifier, self).__init__()\n",
        "        # ResNet18をベースに使用\n",
        "        self.resnet = models.resnet18(pretrained=False)\n",
        "        # 最終層を2クラス分類用に変更\n",
        "        num_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "def load_model():\n",
        "    model = FruitClassifier()\n",
        "    # strict=Falseを追加して、完全一致でなくても読み込めるようにする\n",
        "    state_dict = torch.load('/content/classification.pth', map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # 学習時と同じ前処理を適用\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = preprocess(image)\n",
        "    return image.unsqueeze(0)\n",
        "\n",
        "def main():\n",
        "    st.title('🍎 リンゴ・イチゴ 判別アプリ 🍓')\n",
        "    st.write('画像をアップロードして、リンゴかイチゴかを判定します')\n",
        "\n",
        "    # モデルのロード\n",
        "    try:\n",
        "        model = load_model()\n",
        "        classes = [\"apple\", \"strawberry\"]\n",
        "\n",
        "        # ファイルアップローダー\n",
        "        uploaded_file = st.file_uploader(\"画像をアップロードしてください\", type=['png', 'jpg', 'jpeg'])\n",
        "\n",
        "        if uploaded_file is not None:\n",
        "            # 画像の表示\n",
        "            image = Image.open(uploaded_file)\n",
        "            st.image(image, caption='アップロードされた画像', use_column_width=True)\n",
        "\n",
        "            # 予測\n",
        "            try:\n",
        "                # 画像の前処理\n",
        "                input_tensor = preprocess_image(image)\n",
        "\n",
        "                # 推論\n",
        "                with torch.no_grad():\n",
        "                    output = model(input_tensor)\n",
        "                    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "                    predicted_class = torch.argmax(probabilities).item()\n",
        "\n",
        "                # 結果の表示\n",
        "                st.write('## 判定結果')\n",
        "                st.write(f'この画像は「**{classes[predicted_class]}**」です')\n",
        "\n",
        "                # 確率の表示\n",
        "                st.write('### 確率')\n",
        "                for i, prob in enumerate(probabilities):\n",
        "                    st.write(f'{classes[i]}: {prob.item()*100:.2f}%')\n",
        "                    # プログレスバーで視覚化\n",
        "                    st.progress(prob.item())\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error('画像の処理中にエラーが発生しました。')\n",
        "                st.write(f'エラー詳細: {str(e)}')\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error('モデルの読み込み中にエラーが発生しました。')\n",
        "        st.write(f'エラー詳細: {str(e)}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFJHRp7psDsR",
        "outputId": "b238640b-8e5e-4c2c-f417-53999b248212"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-27 07:54:20.422 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.568 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-01-27 07:54:20.573 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.575 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.579 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-4-2346fef7131b>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/classification.pth', map_location=torch.device('cpu'))\n",
            "2025-01-27 07:54:21.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Streamlitアプリの起動とngrokトンネルの作成\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "GDkDgaD3t4Ev"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 新しい接続を作成\n",
        "# バインドアドレスを明示的に指定\n",
        "public_url = ngrok.connect(addr=\"127.0.0.1:8501\", proto=\"http\")\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8ta7DLXsF_p",
        "outputId": "26acf0a3-fbb7-41de-bbc1-c620595b2b91"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://9599-34-23-119-185.ngrok-free.app\" -> \"http://127.0.0.1:8501\"\n"
          ]
        }
      ]
    }
  ]
}