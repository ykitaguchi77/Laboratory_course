{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkff8v05yaE8SFpL1efxFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Laboratory_course/blob/master/12.%20web%E3%82%A2%E3%83%97%E3%83%AA%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Streamlit test app**"
      ],
      "metadata": {
        "id": "mN2YVgvkkPJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WU0aF9uuOjY",
        "outputId": "88f6e519-50aa-4e94-9e72-46d8ca12f3f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KwZ0cx8ZkOgC",
        "outputId": "e12bf444-d453-48ce-e139-a4e756e1dbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m829.3/829.3 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install streamlit --q\n",
        "!pip install pyngrok --q\n",
        "!pip install streamlit-option-menu --q\n",
        "\n",
        "# 2. ngrokã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ngrokã®Authtokenè¨­å®š (åˆå›ã®ã¿å¿…è¦)\n",
        "ngrok.set_auth_token('ngrok api code here')\n",
        "\n",
        "# 3. ã‚µãƒ³ãƒ—ãƒ«ã®Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/drive/MyDrive/AI_laboratory_course/classification.pth\", \"/content\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s3QHNmzCubto",
        "outputId": "0c9c4eb4-616a-4177-8443-4fb97f044bd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/classification.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©\n",
        "class FruitClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FruitClassifier, self).__init__()\n",
        "        # ResNet18ã‚’ãƒ™ãƒ¼ã‚¹ã«ä½¿ç”¨\n",
        "        self.resnet = models.resnet18(pretrained=False)\n",
        "        # æœ€çµ‚å±¤ã‚’2ã‚¯ãƒ©ã‚¹åˆ†é¡ç”¨ã«å¤‰æ›´\n",
        "        num_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "def load_model():\n",
        "    model = FruitClassifier()\n",
        "    # strict=Falseã‚’è¿½åŠ ã—ã¦ã€å®Œå…¨ä¸€è‡´ã§ãªãã¦ã‚‚èª­ã¿è¾¼ã‚ã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
        "    state_dict = torch.load('/content/classification.pth', map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # å­¦ç¿’æ™‚ã¨åŒã˜å‰å‡¦ç†ã‚’é©ç”¨\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = preprocess(image)\n",
        "    return image.unsqueeze(0)\n",
        "\n",
        "def main():\n",
        "    st.title('ğŸ ãƒªãƒ³ã‚´ãƒ»ã‚¤ãƒã‚´ åˆ¤åˆ¥ã‚¢ãƒ—ãƒª ğŸ“')\n",
        "    st.write('ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ãƒªãƒ³ã‚´ã‹ã‚¤ãƒã‚´ã‹ã‚’åˆ¤å®šã—ã¾ã™')\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
        "    try:\n",
        "        model = load_model()\n",
        "        classes = [\"apple\", \"strawberry\"]\n",
        "\n",
        "        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼\n",
        "        uploaded_file = st.file_uploader(\"ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\", type=['png', 'jpg', 'jpeg'])\n",
        "\n",
        "        if uploaded_file is not None:\n",
        "            # ç”»åƒã®è¡¨ç¤º\n",
        "            image = Image.open(uploaded_file)\n",
        "            st.image(image, caption='ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ', use_column_width=True)\n",
        "\n",
        "            # äºˆæ¸¬\n",
        "            try:\n",
        "                # ç”»åƒã®å‰å‡¦ç†\n",
        "                input_tensor = preprocess_image(image)\n",
        "\n",
        "                # æ¨è«–\n",
        "                with torch.no_grad():\n",
        "                    output = model(input_tensor)\n",
        "                    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "                    predicted_class = torch.argmax(probabilities).item()\n",
        "\n",
        "                # çµæœã®è¡¨ç¤º\n",
        "                st.write('## åˆ¤å®šçµæœ')\n",
        "                st.write(f'ã“ã®ç”»åƒã¯ã€Œ**{classes[predicted_class]}**ã€ã§ã™')\n",
        "\n",
        "                # ç¢ºç‡ã®è¡¨ç¤º\n",
        "                st.write('### ç¢ºç‡')\n",
        "                for i, prob in enumerate(probabilities):\n",
        "                    st.write(f'{classes[i]}: {prob.item()*100:.2f}%')\n",
        "                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§è¦–è¦šåŒ–\n",
        "                    st.progress(prob.item())\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error('ç”»åƒã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚')\n",
        "                st.write(f'ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}')\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error('ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚')\n",
        "        st.write(f'ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFJHRp7psDsR",
        "outputId": "b238640b-8e5e-4c2c-f417-53999b248212"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-27 07:54:20.422 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.568 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-01-27 07:54:20.573 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.575 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.579 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:20.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-4-2346fef7131b>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/classification.pth', map_location=torch.device('cpu'))\n",
            "2025-01-27 07:54:21.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-27 07:54:21.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Streamlitã‚¢ãƒ—ãƒªã®èµ·å‹•ã¨ngrokãƒˆãƒ³ãƒãƒ«ã®ä½œæˆ\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "GDkDgaD3t4Ev"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æ–°ã—ã„æ¥ç¶šã‚’ä½œæˆ\n",
        "# ãƒã‚¤ãƒ³ãƒ‰ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š\n",
        "public_url = ngrok.connect(addr=\"127.0.0.1:8501\", proto=\"http\")\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8ta7DLXsF_p",
        "outputId": "26acf0a3-fbb7-41de-bbc1-c620595b2b91"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://9599-34-23-119-185.ngrok-free.app\" -> \"http://127.0.0.1:8501\"\n"
          ]
        }
      ]
    }
  ]
}