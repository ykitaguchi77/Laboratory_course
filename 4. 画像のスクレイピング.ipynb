{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/FcPjlHpiUPvripTRuhP4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Laboratory_course/blob/master/4.%20%E7%94%BB%E5%83%8F%E3%81%AE%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**画像のスクレイピング**\n",
        "\n"
      ],
      "metadata": {
        "id": "25UMQJsL7UPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**iCrawlerを使う方法**\n",
        "\n",
        "https://atmarkit.itmedia.co.jp/ait/articles/2010/28/news018.html\n",
        "\n",
        "公式： https://icrawler.readthedocs.io/en/latest/builtin.html"
      ],
      "metadata": {
        "id": "iMH1ZVOtriop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "import os\n",
        "\n",
        "# List of keywords\n",
        "keywords = [\"cat\", \"dog\", \"bird\"]\n",
        "max_num = 10\n",
        "\n",
        "for keyword in keywords:\n",
        "    output_dir = f\"/content/{keyword}\"\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    crawler = BingImageCrawler(storage={\"root_dir\": output_dir})\n",
        "    crawler.crawl(keyword=keyword, max_num=max_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfZC5Uv_r87o",
        "outputId": "434b5ecf-f2c0-4f73-9bdc-7a8da4eb5f12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: icrawler in /usr/local/lib/python3.10/dist-packages (0.6.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from icrawler) (6.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Exception caught when downloading file https://i1.wp.com/www.ucityinbloom.org/wp-content/uploads/2015/02/american-goldfinch-male.jpg, error: HTTPSConnectionPool(host='i1.wp.com', port=443): Read timed out. (read timeout=5), remaining retry times: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Requestsを用いる方法**"
      ],
      "metadata": {
        "id": "R975p35iSWJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "def download_images(query, number_of_images):\n",
        "    url = f\"https://www.google.com/search?q={query}&sca_esv=596760372&tbm=isch&sxsrf=ACQVn08jqA_YQTJvXzWkTPH7ZTUxMvP7Tw:1704771354888&source=lnms&sa=X&ved=2ahUKEwiV1p-YsM-DAxVqi68BHcgqDX4Q_AUoAXoECAEQAw&biw=1536&bih=754&dpr=2\"\n",
        "\n",
        "    # Send a request and get the HTML content\n",
        "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    html = response.text\n",
        "\n",
        "    # Parse the HTML using BeautifulSoup\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    images = soup.find_all('img')\n",
        "\n",
        "    # Create a directory to save images\n",
        "    os.makedirs('images', exist_ok=True)\n",
        "\n",
        "    # Download the first 10 images\n",
        "    for i, img in enumerate(images[:number_of_images]):\n",
        "        img_url = img['src']\n",
        "\n",
        "        try:\n",
        "            img_data = requests.get(img_url).content\n",
        "            with open(f'images/apple_{i+1}.jpg', 'wb') as file:\n",
        "                file.write(img_data)\n",
        "            print(f'Downloaded image {i+1}')\n",
        "        except:\n",
        "            print(\"download error\")\n",
        "            pass\n",
        "\n",
        "download_images('りんご', 10)\n"
      ],
      "metadata": {
        "id": "TTWvbDZ5r9F_",
        "outputId": "ad5b5493-f4cf-46a8-cf0e-5fa69f70eb94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download error\n",
            "Downloaded image 2\n",
            "Downloaded image 3\n",
            "Downloaded image 4\n",
            "Downloaded image 5\n",
            "Downloaded image 6\n",
            "Downloaded image 7\n",
            "Downloaded image 8\n",
            "Downloaded image 9\n",
            "Downloaded image 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "\n",
        "def download_original_images(query, number_of_images):\n",
        "    url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
        "\n",
        "    # Send a request and get the HTML content\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    html = response.text\n",
        "\n",
        "\n",
        "    # Parse the HTML using BeautifulSoup\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    # Extract the JavaScript where the image data is located\n",
        "    script = soup.find(\"script\", text=re.compile(\"AF_initDataCallback\"))\n",
        "\n",
        "    data = re.search(r\"AF_initDataCallback\\((.*?)\\);\", script.string).group(1)\n",
        "\n",
        "    # Extract the required data\n",
        "    data_json = json.loads(data)\n",
        "    image_data = data_json['data'][31][0][12][2]\n",
        "\n",
        "    # Create a directory to save images\n",
        "    os.makedirs('images', exist_ok=True)\n",
        "\n",
        "    # Download the specified number of images\n",
        "    for i, img in enumerate(image_data[:number_of_images]):\n",
        "        img_url = img[1][3][0]\n",
        "\n",
        "        try:\n",
        "            img_data = requests.get(img_url, headers=headers).content\n",
        "            with open(f'images/image_{i+1}.jpg', 'wb') as file:\n",
        "                file.write(img_data)\n",
        "            print(f'Downloaded image {i+1}')\n",
        "        except Exception as e:\n",
        "            print(f\"Download error for image {i+1}: {e}\")\n",
        "\n",
        "download_original_images('りんご', 10)\n"
      ],
      "metadata": {
        "id": "AKE0Gyb1X1Bw",
        "outputId": "18e33dcc-355e-4215-e7b4-648355ce212a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-bc1a9fac33d2>:20: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  script = soup.find(\"script\", text=re.compile(\"AF_initDataCallback\"))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'string'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bc1a9fac33d2>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Download error for image {i+1}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mdownload_original_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'りんご'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-bc1a9fac33d2>\u001b[0m in \u001b[0;36mdownload_original_images\u001b[0;34m(query, number_of_images)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"AF_initDataCallback\\((.*?)\\);\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Extract the required data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'string'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_google_images(query):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"tbm\": \"isch\",\n",
        "        \"hl\": \"en\",\n",
        "        \"gl\": \"us\"\n",
        "    }\n",
        "\n",
        "    html = requests.get(\"https://google.com/search\", params=params, headers=headers, timeout=30)\n",
        "    soup = BeautifulSoup(html.text, \"lxml\")\n",
        "\n",
        "    # Extracting inline JSON from script tags\n",
        "    all_script_tags = soup.select(\"script\")\n",
        "    matched_images_data = \"\".join(re.findall(r\"AF_initDataCallback\\(([^<]+)\\);\", str(all_script_tags)))\n",
        "\n",
        "    # Parsing JSON data\n",
        "    matched_images_data_fix = json.dumps(matched_images_data)\n",
        "    matched_images_data_json = json.loads(matched_images_data_fix)\n",
        "\n",
        "    # Extracting image data\n",
        "    matched_google_image_data = re.findall(r'\\\"b-GRID_STATE0\\\"(.*)sideChannel:\\s?{}}', matched_images_data_json)\n",
        "\n",
        "    # Extracting thumbnails\n",
        "    matched_google_images_thumbnails = \", \".join(\n",
        "        re.findall(r'\\[\\\"(https\\:\\/\\/encrypted-tbn0\\.gstatic\\.com\\/images\\?.*?)\\\",\\d+,\\d+\\]',\n",
        "                   str(matched_google_image_data))).split(\", \")\n",
        "    thumbnails = [bytes(bytes(thumbnail, \"ascii\").decode(\"unicode-escape\"), \"ascii\").decode(\"unicode-escape\") for thumbnail in matched_google_images_thumbnails]\n",
        "\n",
        "    # Extracting full resolution images\n",
        "    removed_matched_google_images_thumbnails = re.sub(\n",
        "            r'\\[\\\"(https\\:\\/\\/encrypted-tbn0\\.gstatic\\.com\\/images\\?.*?)\\\",\\d+,\\d+\\]', \"\", str(matched_google_image_data))\n",
        "    matched_google_full_resolution_images = re.findall(r\"(?:'|,),\\[\\\"(https:|http.*?)\\\",\\d+,\\d+\\]\", removed_matched_google_images_thumbnails)\n",
        "    full_res_images = [bytes(bytes(img, \"ascii\").decode(\"unicode-escape\"), \"ascii\").decode(\"unicode-escape\") for img in matched_google_full_resolution_images]\n",
        "\n",
        "    return full_res_images\n",
        "\n",
        "# Using the function\n",
        "images = scrape_google_images(\"tower\")\n",
        "print(images)\n"
      ],
      "metadata": {
        "id": "J57c33lLZm2R",
        "outputId": "fbe9b1ad-95d5-4d34-d1ee-21998c91fec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://upload.wikimedia.org/wikipedia/commons/3/3e/Tokyo_Sky_Tree_2012.JPG', 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Tour_Eiffel_Wikimedia_Commons_%28cropped%29.jpg/640px-Tour_Eiffel_Wikimedia_Commons_%28cropped%29.jpg', 'https://cdn.britannica.com/54/75854-050-E27E66C0/Eiffel-Tower-Paris.jpg', 'https://www.ubm-development.com/magazin/wp-content/uploads/2021/12/S_TernaryTower_1.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Willis_Tower_From_Lake.jpg/1200px-Willis_Tower_From_Lake.jpg', 'https://cdn.britannica.com/51/94351-050-86B70FE1/Leaning-Tower-of-Pisa-Italy.jpg', 'https://www.great-towers.com/themes/worldtower/assets/images/about/1.jpg', 'https://skyscraper.org/supertall/wp-content/uploads/sites/2/2021/11/BJ0618-02-scaled.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Canton_Tower_20220626_%28cropped_2%29.jpg/640px-Canton_Tower_20220626_%28cropped_2%29.jpg', 'https://i.natgeofe.com/k/6d4021bf-832e-49f6-b898-27b7fcd7cbf7/eiffel-tower-ground-up_3x4.jpg', 'https://cdn.britannica.com/88/80588-050-8D944BFE/Leaning-Tower-of-Pisa-Italy.jpg', 'https://images.skyscrapercenter.com/building/Autograph2220720-010744.jpeg', 'https://hrp.imgix.net/https%3A%2F%2Fhistoricroyalpalaces.picturepark.com%2FGo%2FELBKu34c%2FV%2F6059%2F1?auto=format&s=81523f11707f61ef8dccc527e7d897f9', 'https://asset.japan.travel/image/upload/v1646014276/tokyo/H_00658_001.jpg', 'https://nt.global.ssl.fastly.net/binaries/content/gallery/website/national/regions/wales/library/paxtons-tower-carmarthenshire-wales-1627409.jpg', 'https://images.unsplash.com/photo-1510855475067-adc50682ce27?q=80&w=1000&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8Y2FzdGxlJTIwdG93ZXJ8ZW58MHx8MHx8fDA%3D', 'https://media.cntraveler.com/photos/58de89946c3567139f9b6cca/16:9/w_2560%2Cc_limit/GettyImages-468366251.jpg', 'https://media.npr.org/assets/img/2015/05/11/shanghaitower_shenzhonghai_150201_061_custom-ca8f3a5762fdf319be791790f1057882d24ffffe-s1100-c50.jpg', 'https://www.cliffsofmoher.ie/wp-content/uploads/2022/08/OBriens-Tower-photo_master-1.jpg', 'https://upload.wikimedia.org/wikipedia/commons/6/68/Iconic_tower_of_Egypt.jpg', 'https://www.travelandleisure.com/thmb/SPUPzO88ZXq6P4Sm4mC5Xuinoik=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/eiffel-tower-paris-france-EIFFEL0217-6ccc3553e98946f18c893018d5b42bde.jpg', 'https://skyscraper.org/supertall/wp-content/uploads/sites/2/2021/10/2-crt-374x1024-1.jpg', 'https://cdn.sanity.io/images/cxgd3urn/production/48faff9ce744f01887f5d07ebb4cdef3dcf6dd6a-744x992.jpg?w=1200&h=1600&fit=crop&auto=format', 'https://assets.arquitecturaviva.com/assets/uploads/obras/43272/av_25324.webp?h=b8ebdb9c', 'https://www.ubm-development.com/magazin/wp-content/uploads/2021/12/S_TernaryTower_2.jpg', 'https://a.cdn-hotels.com/gdcs/production12/d1492/c6a7a0ad-1702-4552-bb9f-69268476e871.jpg', 'https://visitforres.scot/wp-content/uploads/2021/05/MFH-PLACE-forres-nelsonstower-1276-1024x760.jpg', 'https://media.cnn.com/api/v1/images/stellar/prod/230809122119-03-leaning-tower-pisa-850-closeup.jpg?c=original', 'https://dynamic-media-cdn.tripadvisor.com/media/photo-o/12/a3/e6/97/nelson-s-tower-forres.jpg?w=1200&h=1200&s=1', 'https://static.dezeen.com/uploads/2016/08/diamondtower-ph-thebig5hub.com_dezeen-sq.jpg', 'https://th-thumbnailer.cdn-si-edu.com/hOhEKeDWiv-Kt29ib57-aHSvpKA=/fit-in/1600x0/https%3A%2F%2Ftf-cmsv2-smithsonianmag-media.s3.amazonaws.com%2Ffiler%2Fdb%2Fd6%2Fdbd616d4-f52c-43cb-a9c2-4f77a5dcb2d3%2Feiffel-tower-night.jpg', 'https://visitduluth.com/wp-content/uploads/2023/07/DLTH21_FallShoot-MH_EngerTower_2-1-scaled.jpg', 'https://static.nationalgeographic.co.uk/files/styles/image_3200/public/tower11.jpg?w=1900&h=1709', 'https://static.dezeen.com/uploads/2021/01/tower-c-zaha-hadid-architects-shenzhen-architecture-supertall-skyscrapers_dezeen_2364_col_1-scaled.jpg', 'https://www.tripsavvy.com/thmb/zeE3veOVdhpYlXZUZ0thzUN22xM=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/TowerofPisa-2.jpg-2dde98b91a1e4b08a481b0edd393a7ac.jpg', 'https://www.caesars.com/content/dam/empire/plv/things-to-do/attractions/eiffel-tower-viewing-deck/800x900/effiel-tower800x900.jpg', 'https://www.great-towers.com/sites/default/files/styles/home_page_tower_member/public/2023-04/55.jpg?itok=GhrU2rC_', 'https://www.rct.uk/sites/default/files/styles/rctr-scale-crop-1600-625/public/images/event/lead-image/04/RS613790_8050614%20CF013412-hpr-1600.jpg?itok=s_W03ZUZ', 'https://images.unsplash.com/photo-1511739001486-6bfe10ce785f?q=80&w=1000&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8dG93ZXJ8ZW58MHx8MHx8fDA%3D', 'https://www.cntower.ca/sites/default/files/images/skypod.png', 'https://assets.simpleviewinc.com/simpleview/image/upload/c_fill,f_jpg,h_640,q_65,w_640/v1/clients/toronto/cn_tower_toronto_276bdc20-b872-4384-ad01-f68bb28d6c2d.jpg', 'https://146.20.176.192/r/w1200/upload/09/04/49/untitled-design-374.jpg', 'https://emke.uwm.edu/wp-content/uploads/2018/01/NorthPointWaterTower_02.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Italy_-_Pisa_-_Leaning_Tower.jpg/800px-Italy_-_Pisa_-_Leaning_Tower.jpg', 'https://www.japan-guide.com/g18/3009_01.jpg', 'https://media.architecturaldigest.com/photos/61b23e4380cb28672bc583cf/16:9/w_1280,c_limit/Rendering%209%20(Credit%20-%20Peebles%20Corporation).jpeg', 'https://cdn1.matadornetwork.com/blogs/1/2023/03/Tower-of-London-social.jpg', 'https://res.klook.com/images/fl_lossy.progressive,q_65/c_fill,w_1295,h_863/w_80,x_15,y_15,g_south_west,l_Klook_water_br_trans_yhcmh3/activities/hwttk7vjbmzkdjhlnen4/TokyoTowerObservatoryTicket.jpg', 'https://media.cnn.com/api/v1/images/stellar/prod/231024151024-02-bologna-medieval-tower-file.jpg?c=original', 'https://media.cntraveler.com/photos/592462096af5d360c3ac77bc/16:9/w_2560%2Cc_limit/GettyImages-93299393.jpg', 'https://www.toureiffel.paris/sites/default/files/styles/1200x630/public/2017-11/Sans-titre-1.jpg', 'https://architizer-prod.imgix.net/media/1494968698713139283088358312_Kingdom_Tower_above_the_clouds.jpg?fit=max&w=1680&q=60&auto=format&auto=compress&cs=strip', 'https://img.nmcdn.io/e1/w:800,h:1146,v:1/kpfwp/wp-content/uploads/imported-files/CITIC_Website_Vertical1.jpg?s=e91ffe59', 'https://www.cntower.ca/sites/default/files/images/CNT%20-%20Ext%20-%20Night%20Lighting%20-%2020201009%20-%20074%20crop%202.jpg', 'https://theskydeck.com/wp-content/uploads/2022/01/Tower3-scaled.jpg', 'https://www.webuildvalue.com/wp-content/uploads/2020/08/WE_toureiffel_ENG.jpg', 'https://lp-cms-production.imgix.net/2021-05/shutterstockRF_1321418885.jpg?auto=format&w=1920&h=640&fit=crop&crop=faces,edges&q=75', 'https://canadiangeographic.ca/wp-content/uploads/2022/12/10630485-CN_Tower-1440x994.jpg', 'https://dims.apnews.com/dims4/default/23ed904/2147483647/strip/true/crop/2832x4256+0+0/resize/599x900!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2F7f%2F2efecb3cb21d6d899f0687ce1fc8%2F96589d5490da4a24a15051303e7f6a67', 'https://s3.amazonaws.com/architecture-org/files/buildings/willis-tower-sears-tower-01-ear-2.jpg', 'https://i.ytimg.com/vi/JgkgBZfLu2I/maxresdefault.jpg', 'https://a.cdn-hotels.com/gdcs/production30/d134/efd322da-3735-4c62-a25a-1caef40c9aeb.jpg', 'https://mediaim.expedia.com/destination/9/9bf5e340d2ce501f8f880fe8f71dc0a0.jpg', 'https://eadn-wc02-3591006.nxedge.io/wp-content/uploads/2021/02/Porsche-Design-Tower-Miami-56.jpg', 'https://www.toureiffel.paris/sites/default/files/styles/1200x675/public/actualite/image_principale/histoire_taille_main.jpg?itok=hmZfWl_p', 'https://img.buzzfeed.com/buzzfeed-static/static/2019-01/22/13/enhanced/buzzfeed-prod-web-01/original-27653-1548181866-4.jpg?crop=1980:1036;0,284%26downsize=1250:*', 'https://cdn.vox-cdn.com/thumbor/6YoCQUxzENgvNjyjPd-fLdATXPk=/1400x1050/filters:format(jpeg)/cdn.vox-cdn.com/uploads/chorus_asset/file/25068576/lego_avengers_tower.jpg', 'https://images.adsttc.com/media/images/5037/e052/28ba/0d59/9b00/015a/medium_jpg/stringio.jpg?1414052877', 'https://staticg.sportskeeda.com/editor/2022/12/e168b-16703667409205-1920.jpg?w=840', 'https://as1.ftcdn.net/v2/jpg/01/11/78/64/1000_F_111786431_NfDh6noMXFppaYp6BMh5tu0lx48p5G7J.jpg', 'https://s3.amazonaws.com/architecture-org/files/buildings/willis-tower-sears-tower-03-ear.jpg', 'https://img.nmcdn.io/e1/w:788,h:1128,v:1/kpfwp/wp-content/uploads/imported-files/Lotte_World_Tower_street_view-scaled.jpg?s=8013d1e8', 'https://photos.zillowstatic.com/fp/a37e89e9ecbe8cc754e930c0c95eaae8-full.webp', 'https://cdn.britannica.com/03/152203-004-A1BA21F3/Close-up-Leaning-Tower-of-Pisa-Italy.jpg', 'https://assets.editorial.aetnd.com/uploads/2011/06/gettyimages-142198198.jpg', 'https://news.artnet.com/app/news-upload/2022/12/GettyImages-1362089238-1024x683.jpg', 'https://upload.wikimedia.org/wikipedia/commons/5/58/Tokyo_Tower_2023.jpg', 'https://www.reuters.com/resizer/-tZbgrD99hYS8MQlCRpKHrCqlbk=/960x960/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/AHF2FYISNJO55J6N35YJBZ2JYY.jpg', 'https://skyscraper.org/tallest-towers/wp-content/uploads/sites/7/2020/10/Sears-Tower_02.jpg', 'https://www.momondo.com/himg/2d/fb/31/leonardo-12222-156668028-142343.jpg', 'https://cdn.thecollector.com/wp-content/uploads/2023/04/eiffel-tower-incredible-facts.jpg?width=1400&quality=70', 'https://s3.amazonaws.com/images.skyscrapercenter.com/thumbs/103978_500x650.jpg', 'https://i.insider.com/58d958617d1fb227008b4c7e?width=1067&format=jpeg', 'https://staticg.sportskeeda.com/editor/2022/02/6f219-16449618989691-1920.jpg', 'https://hudsonreporter.com/wp-content/uploads/2022/09/10baybelltowe06-01-scaled.jpeg', 'https://hrp.imgix.net/https%3A%2F%2Fhistoricroyalpalaces.picturepark.com%2FGo%2FynnTGt8d%2FV%2F61191%2F1?auto=format&s=2a431caa3cce2c7c8bea8e2bfb0e3f6d', 'https://osaka-info.jp/spot/images/108608cd19ba1cb3e78b3997c6365239c0474d2c.jpeg', 'https://amazingarchitecture.com/storage/2753/01-tree_tower_archi_nature_co_existing_moshe_katz_architect.jpg', 'https://www.usgbc.org/sites/default/files/Taipei%20101%20Tower-A.jpg', 'https://i.guim.co.uk/img/static/sys-images/Guardian/Pix/maps_and_graphs/2012/5/22/1337697457284/Graphic---Tokyo-Skytree-c-001.gif?width=445&dpr=1&s=none', 'https://cdn.thecollector.com/wp-content/uploads/2023/01/how-tall-is-the-eiffel-tower-facts.jpg?width=1400&quality=70', 'https://i.natgeofe.com/k/04665f4a-3f8d-4b62-8ca3-09ce7dfc5a20/france-eiffel-tower_3x4.jpg', 'https://storage.googleapis.com/pod_public/1300/73536.jpg', 'https://i.ytimg.com/vi/fKN31amyk2o/maxresdefault.jpg', 'https://www.archpaper.com/wp-content/uploads/2021/08/51f82531f06fd6b9230b6696dd33a803.jpg', 'https://people.com/thmb/4Frur8JDY-pwLde8OAAqxdmZmmo=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc():focal(749x203:751x205)/Bologna-Towers-Collapse-120423-tout-053ab218db5c412b853937d942776a92.jpg', 'https://afar.brightspotcdn.com/dims4/default/d2ef925/2147483647/strip/false/crop/800x450+0+25/resize/1200x675!/quality/90/?url=https%3A%2F%2Fafar-media-production-web.s3.us-west-2.amazonaws.com%2Fbrightspot%2F29%2Fc8%2Fc9798cf41c6c4794bca065614af6%2Foriginal-dd3dc5ed159c7f4ebfecb8b7bc40c388.jpg', 'https://www.cntower.ca/sites/default/files/images/explore-cn-tower%20.jpg', 'https://www.gotokyo.org/shared/images/pages/destinations/southern-tokyo/tokyo-tower-and-around/images/xtokyo_tower_new.jpg.pagespeed.ic.5dx26TzNv-.jpg', 'https://media.architecturaldigest.com/photos/640f66ec5d38af65edd18e2c/4:3/w_8012,h_6009,c_limit/GettyImages-1327817863.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**AZURE Bing Searchを用いる方法**\n",
        "\n",
        "準備：\n",
        "- Microsoft AZUREに登録\n",
        "\n",
        "    https://learn.microsoft.com/ja-jp/azure/cognitive-services/bing-web-search/\n",
        "\n",
        "- 左のタブ → リソースの作成 → Bing Search v7を取得\n",
        "\n",
        "- ダッシュボード → キーとエンドポイントからキーを取得する"
      ],
      "metadata": {
        "id": "539gH-qvrOrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Deep_learning/api.txt\") as file:\n",
        "    #text = file.read()\n",
        "    i=1\n",
        "    key = []\n",
        "    while True:\n",
        "        include_break_line = file.readline() #改行が含まれた行\n",
        "        line = include_break_line.rstrip() #改行を取り除く\n",
        "        if line: #keyの読み込み\n",
        "            #print(f'{i}行目：{line}')\n",
        "            key.append(line)\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "bing_api_key = key[13]"
      ],
      "metadata": {
        "id": "Sa4lK_QK7-Uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2e0e2e-896f-4937-bd0a-f785b54eda9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "from requests import exceptions\n",
        "import argparse\n",
        "import requests\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "API_KEY = f\"{bing_api_key}\"\n",
        "MAX_SIZE = 10\n",
        "GROUP_SIZE = 5\n",
        "\n",
        "# 取得したエンドポイントURL\n",
        "URL = \"https://api.bing.microsoft.com/v7.0/images/search\"\n",
        "OUTPUT = '/content/save_dir'\n",
        "\n",
        "if not os.path.isdir(OUTPUT):\n",
        "    os.mkdir(OUTPUT)\n",
        "\n",
        "EXCEPTIONS = set([IOError, FileNotFoundError,\n",
        "    exceptions.RequestException, exceptions.HTTPError,\n",
        "    exceptions.ConnectionError, exceptions.Timeout])\n",
        "\n",
        "search_terms = [\"forest\", \"river\", \"house\"]\n",
        "\n",
        "# set the output csv file name\n",
        "csv_file = \"url_list.csv\"\n",
        "\n",
        "# create the csv file and write the headers\n",
        "with open(csv_file, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Search term', 'Image URL'])\n",
        "\n",
        "# loop over each search term and download images\n",
        "for term in search_terms:\n",
        "    print(f\"[INFO] searching Bing API for '{term}'\")\n",
        "\n",
        "    # create the directory to save the images for the current search term\n",
        "    output_dir = os.path.join(OUTPUT, term)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    headers = {\"Ocp-Apim-Subscription-Key\": API_KEY}\n",
        "    params = {\"q\": term, \"offset\": 0, \"count\": GROUP_SIZE, \"imageType\": \"Photo\", \"color\": \"ColorOnly\"}\n",
        "\n",
        "    # make the search\n",
        "    search = requests.get(URL, headers=headers, params=params)\n",
        "    search.raise_for_status()\n",
        "\n",
        "    # grab the results from the search, including the total number of\n",
        "    # estimated results returned by the Bing API\n",
        "    results = search.json()\n",
        "    est_num_results = min(results[\"totalEstimatedMatches\"], MAX_RESULTS)\n",
        "    print(f\"[INFO] {est_num_results} total results for '{term}'\")\n",
        "\n",
        "    # initialize the total number of images downloaded thus far\n",
        "    total = 0\n",
        "\n",
        "    # loop over the estimated number of results in `GROUP_SIZE` groups\n",
        "    for offset in range(0, est_num_results, GROUP_SIZE):\n",
        "        # update the search parameters using the current offset, then\n",
        "        # make the request to fetch the results\n",
        "        params[\"offset\"] = offset\n",
        "        search = requests.get(URL, headers=headers, params=params)\n",
        "        search.raise_for_status()\n",
        "        results = search.json()\n",
        "\n",
        "        # loop over the results\n",
        "        for v in results[\"value\"]:\n",
        "            # try to download the image\n",
        "            try:\n",
        "                # make a request to download the image\n",
        "                print(\"[INFO] fetching: {}\".format(v[\"contentUrl\"]))\n",
        "                r = requests.get(v[\"contentUrl\"], timeout=30)\n",
        "\n",
        "                # build the path to the output image\n",
        "                ext = v[\"contentUrl\"][v[\"contentUrl\"].rfind(\".\"):]\n",
        "                filename = f\"{term}_{str(total).zfill(3)}{ext}\"\n",
        "                output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "                # write the image to disk\n",
        "                with open(output_path, \"wb\") as f:\n",
        "                    f.write(r.content)\n",
        "\n",
        "                # write the URL to the csv file\n",
        "                with open(csv_file, 'a', newline='') as f:\n",
        "                    writer = csv.writer(f)\n",
        "                    writer.writerow([term, v[\"contentUrl\"]])\n",
        "\n",
        "            # catch any errors that would not unable us to download the\n",
        "            # image\n",
        "            except Exception as e:\n",
        "                print(f\"[INFO] skipping: {v['contentUrl']}\")\n",
        "\n",
        "            # if we have reached the maximum number of images, break out\n",
        "            # of the loop\n",
        "            total += 1\n",
        "            print(f\"{total} images downloaded!\")\n",
        "            if total >= MAX_SIZE:\n",
        "                break\n",
        "\n",
        "        # if we have reached the maximum number of images, break out of\n",
        "        # the loop\n",
        "        if total >= MAX_SIZE:\n",
        "            break\n"
      ],
      "metadata": {
        "id": "c_NgBbvCwOrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Chromedriverを用いる方法**"
      ],
      "metadata": {
        "id": "e0WP5ZQnAfIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium==4.1.0 #新しいバージョンだとエラーが出るので旧バージョンにする"
      ],
      "metadata": {
        "id": "9frhTgD4BYLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoWBLiRVBne3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# これだとサムネイルしか取得できない\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# Search query\n",
        "search_query = \"flowers\"\n",
        "\n",
        "# Number of images to download\n",
        "num_images = 10\n",
        "\n",
        "# Create a new folder for the images\n",
        "if not os.path.exists(search_query):\n",
        "    os.makedirs(search_query)\n",
        "\n",
        "# URL to search Google Images\n",
        "url = f\"https://www.google.com/search?q={search_query}&tbm=isch\"\n",
        "\n",
        "# Send GET request\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML using Beautiful Soup\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all image tags\n",
        "images = soup.find_all('img')\n",
        "\n",
        "# Iterate through the images and download them\n",
        "for i, img in enumerate(images[:num_images]):\n",
        "    url = img['src']\n",
        "    print(i)\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        open(f\"{search_query}/{search_query}_{i}.jpg\", \"wb\").write(response.content)\n",
        "    except:\n",
        "        print(\"download error\")"
      ],
      "metadata": {
        "id": "YRrPYIguIEBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!curl -O https://chromedriver.storage.googleapis.com/110.0.5481.77/chromedriver_linux64.zip #Chromeのバージョンに合ったchromedriverのアドレスを設定\n",
        "!unzip chromedriver_linux64.zip\n",
        "!chmod +x chromedriver\n",
        "!mv chromedriver /usr/local/bin/\n",
        "!pip install selenium\n",
        "\n",
        "from selenium import webdriver\n",
        "\n",
        "# Chromeドライバーの設定\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--disable-gpu')\n",
        "options.add_argument('--disable-browser-side-navigation')\n",
        "\n",
        "# Googleで検索する\n",
        "search_query = 'flowers'\n",
        "url = f\"https://www.google.com/search?q={search_query}&tbm=isch\"\n",
        "browser = webdriver.Chrome('chromedriver',options=options)\n",
        "browser.get(url)\n",
        "\n",
        "\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import base64\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# 画像のURLを取得する\n",
        "soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
        "img_tags = soup.find_all('img', class_='rg_i')\n",
        "\n",
        "\n",
        "urls = []\n",
        "for img in img_tags:\n",
        "    try:\n",
        "        urls.append(img[\"src\"])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "# 画像をダウンロードする\n",
        "if not os.path.exists(search_query):\n",
        "    os.makedirs(search_query)\n",
        "\n",
        "num_images = 10\n",
        "\n",
        "counter = 0\n",
        "for i in range(num_images):\n",
        "    print(urls[i])\n",
        "    image_data = base64.b64decode(urls[i].split(',')[1])\n",
        "\n",
        "    # バイナリデータをBytesIOオブジェクトに書き込む\n",
        "    image_stream = BytesIO(image_data)\n",
        "\n",
        "    # PILで画像オブジェクトを作成する\n",
        "    image = Image.open(image_stream)\n",
        "    image_format = image.format\n",
        "\n",
        "    # 画像のネーミング\n",
        "    num= \"{:04d}\".format(i)\n",
        "    file_name = f\"{search_query}_{num}\"\n",
        "    new_image_path = f\"{search_query}/{file_name}.{image_format}\"\n",
        "\n",
        "\n",
        "    # Save image to file\n",
        "    image.save(new_image_path)\n"
      ],
      "metadata": {
        "id": "RupG3_zyQ7QT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}