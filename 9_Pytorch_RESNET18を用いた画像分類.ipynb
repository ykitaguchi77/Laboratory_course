{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Laboratory_course/blob/master/9_Pytorch_RESNET18%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E7%94%BB%E5%83%8F%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4HYzU9ckXbS"
      },
      "source": [
        "#PyTorch : RESNET18を用いた画像分類\n",
        "\n",
        "http://torch.classcat.com/2018/04/29/pytorch-tutorial-transfer-learning/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyzcteflxK14"
      },
      "source": [
        "#自作データ、Early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sZw9awMlMpC"
      },
      "source": [
        "#Google driveのデータをマウント\n",
        "データの位置\n",
        "/content/drive/My drive/Deep_learning/dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4oE6PwpkNUb"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import shutil\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "np.random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Xvn-zaJSao",
        "outputId": "b6662461-07d3-41ff-d4d7-694f113d575a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#dataset.zipを解凍\n",
        "!date -R\n",
        "!unzip -qq drive/My\\ Drive/AI_laboratory_course/dataset.zip\n",
        "!date -R\n",
        "!ls\n",
        "\n",
        "shutil.move(\"/content/train/appl\", \"/content/appl\")\n",
        "shutil.move(\"/content/train/stra\", \"/content/stra\")\n",
        "shutil.rmtree(\"/content/train\")\n",
        "shutil.rmtree(\"/content/val\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Mon, 27 Jan 2025 01:23:39 +0000\n",
            "Mon, 27 Jan 2025 01:23:44 +0000\n",
            "drive  sample_data  train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#データセットをフォルダ分け"
      ],
      "metadata": {
        "id": "SUaOhze5hdWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "このような形にしたい\n",
        "\n",
        "dog---dog1.jpg\n",
        "    |-dog2.jpg\n",
        "    |-dog3.jpg\n",
        "    |\n",
        "    |-dog300.jpg\n",
        "\n",
        "cat---cat1.jpg\n",
        "    |-cat2.jpg\n",
        "    |-cat3.jpg\n",
        "    |\n",
        "    |-cat300.jpg\n",
        "\n",
        "↓↓\n",
        "\n",
        "train---dog---dog1.jpg\n",
        "      |     |-dog2.jpg\n",
        "      |     |\n",
        "      |     |-dog299.jpg\n",
        "      |\n",
        "      |-cat---cat1.jpg\n",
        "            |-cat2.jpg\n",
        "            |\n",
        "            |-cat298.jpg\n",
        "\n",
        "val-----dog---dog3.jpg\n",
        "      |     |-dog4.jpg\n",
        "      |     |\n",
        "      |     |-dog300.jpg\n",
        "      |\n",
        "      |-cat---cat3.jpg\n",
        "            |-cat4.jpg\n",
        "            |\n",
        "            |-cat300.jpg\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uaAaVZAIhkco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainとvalにランダムに分けるスクリプト\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class_names = [\"appl\", \"stra\"] ###←ここを変更してください\n",
        "parent_dir = f'/content' ###←ここを変更してください\n",
        "\n",
        "for class_name in class_names:\n",
        "\n",
        "    # location of the dataset\n",
        "    orig_dir = f'{parent_dir}/{class_name}'\n",
        "\n",
        "    # get the list of all files in the folder\n",
        "    all_files = glob.glob(f\"{orig_dir}/*\")\n",
        "\n",
        "    print(f\"len_all_files: {len(all_files)}\")\n",
        "\n",
        "    # split the list into train and validation sets\n",
        "    train_files, val_files = train_test_split(all_files, test_size=0.2, random_state=0)\n",
        "\n",
        "    # create the train and validation folders if they don't exist\n",
        "    train_folder = f'/content/train/{class_name}'\n",
        "    val_folder = f'/content/val/{class_name}'\n",
        "    if os.path.exists(train_folder):\n",
        "        shutil.rmtree(train_folder)\n",
        "    os.makedirs(train_folder)\n",
        "    if os.path.exists(val_folder):\n",
        "        shutil.rmtree(val_folder)\n",
        "    os.makedirs(val_folder)\n",
        "\n",
        "    # copy the files from the dataset folder to the train and validation folders\n",
        "    for file in train_files:\n",
        "        new_location = f\"{train_folder}/{os.path.basename(file)}\"\n",
        "        shutil.copy(file, new_location)\n",
        "\n",
        "    for file in val_files:\n",
        "        new_location = os.path.join(val_folder, os.path.basename(file))\n",
        "        shutil.copy(file, new_location)"
      ],
      "metadata": {
        "id": "3rd3Vc1Eie0N",
        "outputId": "17571413-13c7-4d8f-902a-c16144b4cab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len_all_files: 252\n",
            "len_all_files: 252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGMZmsSGkjOC"
      },
      "source": [
        "#データをロードする\n",
        "データをロードするために torchvision と torch.utils.data パッケージを使用します。訓練用データセットと評価用データセットは4:1ぐらいにします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xcl55uJknDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4adcbfa9-cbe7-4630-9ea2-e3fac752d42c"
      },
      "source": [
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "\n",
        "\"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "\"\"\"\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.5,1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = '/content'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "print(class_names)\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_train:\"+str(len(os.listdir(path= data_dir + '/train/'+class_names[k]))))\n",
        "    k+=1\n",
        "k=0\n",
        "for i in class_names:\n",
        "    print(class_names[k]+\"_val:\"+str(len(os.listdir(path= data_dir + '/val/'+class_names[k]))))\n",
        "    k+=1\n",
        "\n",
        "print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "print(\"validating data set_total：\"+str(len(image_datasets['val'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['appl', 'stra']\n",
            "appl_train:201\n",
            "stra_train:201\n",
            "appl_val:51\n",
            "stra_val:51\n",
            "training data set_total：402\n",
            "validating data set_total：102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQowdDzHmTdT"
      },
      "source": [
        "#少数の画像を可視化する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1YMGAaimaLK"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9q7wSBWaQ_t"
      },
      "source": [
        "#Define the Early Stopping Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U78WhRfxaRH7"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSq-oHh4mobp"
      },
      "source": [
        "#モデルを訓練する\n",
        "さて、モデルを訓練するための一般的な関数を書きましょう。ここで、次を示します :\n",
        "\n",
        "学習率をスケジューリングする<br>\n",
        "ベスト・モデルをセーブする<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO7mosiCmrq6"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_loss = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_loss = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # record train_loss and valid_loss\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            if phase == 'val':\n",
        "                valid_loss.append(epoch_loss)\n",
        "            #print(train_loss)\n",
        "            #print(valid_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      # early_stopping needs the validation loss to check if it has decresed,\n",
        "      # and if it has, it will make a checkpoint of the current model\n",
        "        if phase == 'val':\n",
        "            early_stopping(epoch_loss, model)\n",
        "\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss, valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URMZLxsvmyZS"
      },
      "source": [
        "#モデル予測を可視化する\n",
        "少数の画像のための予測を表示するための一般的な関数。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga3kWm5Nm1Mj"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhvTS0Y8m3HD"
      },
      "source": [
        "#convnet を再調整する\n",
        "モデルをロードして最後の完全結合層をリセットします。<br>\n",
        "※pretrained = False　→事前訓練していない状態になります<br>\n",
        "※pretrained = True　→事前訓練しされた状態"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s7odcUUm-hT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78549c8f-feba-4279-e979-18279648d83e"
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 64.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaLCTzTLnBSL"
      },
      "source": [
        "#訓練と評価\n",
        "CPU 上でおよそ 15-25 分かかるはずです。けれども GPU 上なら、1 分もかかりません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ijHctNfnD_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e81a627-7233-4f7a-b31e-cc99530b7c77"
      },
      "source": [
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, patience=5, num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4309 Acc: 0.8234\n",
            "val Loss: 0.1415 Acc: 0.9706\n",
            "Validation loss decreased (inf --> 0.141545).  Saving model ...\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.1464 Acc: 0.9577\n",
            "val Loss: 0.0838 Acc: 0.9706\n",
            "Validation loss decreased (0.141545 --> 0.083803).  Saving model ...\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.1028 Acc: 0.9552\n",
            "val Loss: 0.0753 Acc: 0.9804\n",
            "Validation loss decreased (0.083803 --> 0.075328).  Saving model ...\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.0934 Acc: 0.9776\n",
            "val Loss: 0.0740 Acc: 0.9706\n",
            "Validation loss decreased (0.075328 --> 0.074033).  Saving model ...\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.0505 Acc: 0.9851\n",
            "val Loss: 0.0549 Acc: 0.9804\n",
            "Validation loss decreased (0.074033 --> 0.054871).  Saving model ...\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.0660 Acc: 0.9701\n",
            "val Loss: 0.0495 Acc: 0.9804\n",
            "Validation loss decreased (0.054871 --> 0.049539).  Saving model ...\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.0435 Acc: 0.9900\n",
            "val Loss: 0.0466 Acc: 0.9804\n",
            "Validation loss decreased (0.049539 --> 0.046626).  Saving model ...\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.0411 Acc: 0.9950\n",
            "val Loss: 0.0504 Acc: 0.9804\n",
            "EarlyStopping counter: 1 out of 5\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.0493 Acc: 0.9876\n",
            "val Loss: 0.0511 Acc: 0.9902\n",
            "EarlyStopping counter: 2 out of 5\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.0371 Acc: 0.9876\n",
            "val Loss: 0.0466 Acc: 0.9804\n",
            "Validation loss decreased (0.046626 --> 0.046554).  Saving model ...\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.0331 Acc: 0.9925\n",
            "val Loss: 0.0471 Acc: 0.9804\n",
            "EarlyStopping counter: 1 out of 5\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.0606 Acc: 0.9826\n",
            "val Loss: 0.0478 Acc: 0.9804\n",
            "EarlyStopping counter: 2 out of 5\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.0420 Acc: 0.9876\n",
            "val Loss: 0.0486 Acc: 0.9804\n",
            "EarlyStopping counter: 3 out of 5\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.0577 Acc: 0.9801\n",
            "val Loss: 0.0578 Acc: 0.9804\n",
            "EarlyStopping counter: 4 out of 5\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.0388 Acc: 0.9900\n",
            "val Loss: 0.0525 Acc: 0.9804\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "Training complete in 1m 60s\n",
            "Best val Acc: 0.990196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFOb4iPzXpTx"
      },
      "source": [
        "#訓練結果のグラフ化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrWRhUFoGZYS"
      },
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1\n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 0.5) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#fig.savefig('loss_plot.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzP0fvLCoWNS"
      },
      "source": [
        "visualize_model(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbjpEmUCr7nb"
      },
      "source": [
        "#Test datasetにおける正解率を（改めて）計算"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 正解ラベルと予測結果を格納する変数を用意する\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "class_names = [\"appl\", \"stra\"]\n",
        "show_image = True\n",
        "reverse_augmentation = True\n",
        "\n",
        "\n",
        "# def de_normalize(array):\n",
        "#     for t, m, s in zip(array, mean, std):\n",
        "#         t.mul_(s).add_(m)\n",
        "#     return array\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "\n",
        "# モデルを評価するデータセットに対して、正解率を計算する\n",
        "with torch.no_grad():\n",
        "    for data, target in dataloaders[\"val\"]:\n",
        "        # dataをモデルに入力し、予測結果を出力する\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        outputs = model_ft(data)\n",
        "\n",
        "        # 予測結果から最も確信度が高いクラスを選ぶ\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # 正解ラベルと予測結果を格納する\n",
        "        y_true.extend(target.tolist())\n",
        "        y_pred.extend(predicted.tolist())\n",
        "\n",
        "        # if show_image == True:\n",
        "        #     data = data.cpu().detach().numpy().copy()\n",
        "        #     data = data / 2 + 0.5\n",
        "        #     plt.imshow(data)\n",
        "        #     plt.show()\n",
        "\n",
        "        if show_image == True:\n",
        "            # Convert the PyTorch tensor to a numpy array\n",
        "            data = data.cpu().permute(0, 2, 3, 1).detach().numpy().copy()\n",
        "            if reverse_augmentation == True:\n",
        "                mean = [0.485, 0.456, 0.406]\n",
        "                std = [0.229, 0.224, 0.225]\n",
        "                data *= std\n",
        "                data += mean\n",
        "                data *= 255\n",
        "                data = np.clip(data, 0, 255).astype(np.uint8)\n",
        "            else:\n",
        "                data = np.clip(data, 0, 1)\n",
        "\n",
        "\n",
        "\n",
        "            batch_size = 20\n",
        "            for i in range(batch_size):\n",
        "                try: #batch size端数のエラー回避\n",
        "                    plt.imshow(data[i])\n",
        "                    plt.show()\n",
        "                    print(f\"label: {class_names[y_true[i]]}, pred: {class_names[y_pred[i]]}\")\n",
        "                    print(\"\")\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "# 混同行列を計算する\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# 各クラスの正解率を計算する\n",
        "for i, class_name in enumerate(class_names):\n",
        "    class_accuracy = cm[i, i] / sum(cm[i, :])\n",
        "    print('Class {} Accuracy: {:.2f}%'.format(class_name, class_accuracy * 100))"
      ],
      "metadata": {
        "id": "SA39-0iF9WjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルを評価するデータセットに対して、正解率を計算する\n",
        "with torch.no_grad():\n",
        "\n",
        "    # dataをモデルに入力し、予測結果を出力する\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    outputs = model_ft(data)\n",
        "\n",
        "    # 予測結果から最も確信度が高いクラスを選ぶ\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # 正解ラベルと予測結果を格納する\n",
        "    y_true.extend(target.tolist())\n",
        "    y_pred.extend(predicted.tolist())"
      ],
      "metadata": {
        "id": "YbkhGLf3VOu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrx3dC_b4GrU"
      },
      "source": [
        "#モデルの保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruFy-yWh4FT6"
      },
      "source": [
        "PATH = '/content/drive/My Drive/AI_laboratory_course/classification.pth'\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxiGdz5dn-5c"
      },
      "source": [
        "#演習\n",
        "1. Pretrained model = Trueに変更して、転移学習をしてみましょう\n",
        "2. 自作のデータセットを用いて分類を行ってみましょう\n",
        "3. パラメータ（batch size、lr、Patienceなど）をいじってみて学習効率の変化を観察しましょう"
      ]
    }
  ]
}